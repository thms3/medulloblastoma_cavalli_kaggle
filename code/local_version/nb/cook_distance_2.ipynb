{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8ec6823-d6cb-42ed-9d12-4f66f931f590",
   "metadata": {},
   "source": [
    "# [GSE85217] Tracking outliers - Cook's Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b65d5003-3944-40b8-868b-e5953a59c18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m[C 2024-11-05 17:37:57.034 ServerApp]\u001b[m No such file or directory: /home/thomas/Documents/git/medulloblastoma_cavalli_kaggle/code/local_version/nb/enable\n"
     ]
    }
   ],
   "source": [
    "!jupyter-lab enable widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9443b5-8101-4610-b4b4-62bab2e4f293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 17:38:03.469260: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-05 17:38:03.550920: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-05 17:38:03.575827: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-05 17:38:03.698609: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-05 17:38:05.043312: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# lib\n",
    "#import modin.pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import umap\n",
    "\n",
    "# fig\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# local lib\n",
    "import sys\n",
    "sys.path.insert(1,'/home/thomas/Documents/git/medulloblastoma_cavalli_kaggle/code/local_version/fun')\n",
    "\n",
    "from parser import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bd985d0-b751-4866-bd34-f99827540ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3cf2390-024e-4acd-84fc-5bfed7eff211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f\n",
    "from statsmodels.formula.api import glm\n",
    "import statsmodels.api as sm\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "115e2d16-0f80-4b98-abc2-79daeccee0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data='/home/thomas/Documents/git/medulloblastoma_cavalli_kaggle/data/in/'\n",
    "path_exp_mat = path_data + 'GSE85217_M_exp_763_MB_SubtypeStudy_TaylorLab_parsed.txt'\n",
    "path_meta = path_data + 'GSE85217_Cavalli_subgroups_information_parsed.csv'\n",
    "\n",
    "data=Data()\n",
    "data.add_exp_mat(path_exp_mat,index_col=\"genes_name\")\n",
    "data.add_meta(path_meta=path_meta,index_col=\"samples_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a8c11e8-d810-4227-8930-49339d313267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import f\n",
    "from statsmodels.formula.api import glm\n",
    "import statsmodels.api as sm\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from multiprocessing import shared_memory\n",
    "import psutil\n",
    "import time\n",
    "from threading import Thread\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3844ae32-91a7-41ca-ac2b-be333e9c163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "729eda52-f7a7-42de-ad57-1adab6908100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM Usage: 58.2% | CPU Usage: 12.7%\n",
      "RAM Usage: 58.3% | CPU Usage: 15.2%\n",
      "RAM Usage: 58.3% | CPU Usage: 9.9%\n",
      "RAM Usage: 58.3% | CPU Usage: 12.1%\n",
      "RAM Usage: 58.3% | CPU Usage: 12.1%\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "class ResourceMonitor:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.stop_event = threading.Event()\n",
    "        self.monitor_thread = threading.Thread(target=self.monitor_resources)\n",
    "        self.monitor_thread.deamon = True\n",
    "\n",
    "    def monitor_resources(self):\n",
    "        while not self.stop_event.is_set():\n",
    "            print(f\"RAM Usage: {psutil.virtual_memory().percent}% | CPU Usage: {psutil.cpu_percent()}%\")\n",
    "            time.sleep(1)\n",
    "\n",
    "    def start(self):\n",
    "        # Start the deamon thread\n",
    "        self.monitor_thread.start()\n",
    "\n",
    "    def stop(self):\n",
    "        # Signal the thread to stop and wait for it to finish\n",
    "        self.stop_event.set()\n",
    "        self.monitor_thread.join()\n",
    "\n",
    "    \n",
    "# Usage example:\n",
    "monitor = ResourceMonitor()\n",
    "monitor.start()\n",
    "\n",
    "# Main processing code goes here\n",
    "time.sleep(5)  # Simulate work\n",
    "\n",
    "# Stop the monitor when processing is done\n",
    "monitor.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3d31ddb-3b56-4153-903d-1e7b35dccfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CookDistanceAnalyzer:\n",
    "\n",
    "    def __init__(self, n_cores=6, batch_size = 100):\n",
    "        self.n_cores = n_cores\n",
    "        self.batch_size = batch_size\n",
    "        self.resource_monitor = ResourceMonitor()\n",
    "        \n",
    "    @staticmethod\n",
    "    def _print_mp(text):\n",
    "        print(text)\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "    @classmethod\n",
    "    def worker_mp(cls,job_id:int,worker,**kwargs):\n",
    "        cls._print_mp(\"Processing chunk: \"+str(job))\n",
    "        output = worker(**kwargs)\n",
    "        cls._print_mp(\"Finished chunk: \"+str(job))\n",
    "        return output\n",
    "        \n",
    "    @staticmethod\n",
    "    def trimfn(x: float) -> int:\n",
    "        return 2 if x >= 23.5 else 1 if x >= 3.5 else 0\n",
    "\n",
    "    @staticmethod\n",
    "    def trimmed_mean(x: np.ndarray, trim: float = 0.1, **kwargs) -> np.ndarray:\n",
    "    \n",
    "        assert trim <= 0.5\n",
    "    \n",
    "        kwargs.setdefault('axis',0)\n",
    "        \n",
    "        axis = kwargs.get(\"axis\")\n",
    "        s = np.sort(x,**kwargs)\n",
    "        n = x.shape[axis]\n",
    "        ntrim = math.floor(n * trim)\n",
    "        return np.take(s, np.arange(ntrim, n - ntrim), axis).mean(**kwargs)\n",
    "\n",
    "    def chunkify_exp_mat(self,exp_mat,design_series):\n",
    "\n",
    "            ns = design_series.value_counts()\n",
    "            trimratio = (1 / 3, 1 / 4, 1 / 8)\n",
    "\n",
    "            for var in design_series.unique():\n",
    "                lvl = self.trimfn(ns[var])\n",
    "                yield exp_mat[design_series == var, :], lvl\n",
    "\n",
    "    def trimmed_design_variance(self, exp_mat: np.ndarray, design_series: pd.Series) -> np.ndarray:\n",
    "        return np.array([self.process_variance(exp_mat,lvl) for exp_mat,lvl in self.chunkify_exp_mat(np.array(exp_mat),design_series)]).mean(0)\n",
    "            \n",
    "            \n",
    "    def process_variance(self,exp_mat:np.ndarray,lvl:int,trim_ratio=(1 / 3, 1 / 4, 1 / 8),scale=[2.04, 1.86, 1.51]):\n",
    "        var_means = self.trimmed_mean(x=exp_mat, trim=trim_ratio[lvl], axis = 0)\n",
    "        sqerror_var = (exp_mat - var_means) ** 2\n",
    "        variance_means = self.trimmed_mean(sqerror_var, trim=trim_ratio[lvl], axis=0)\n",
    "        variance_means*=scale[lvl]\n",
    "        return variance_means\n",
    "\n",
    "    def robust_method_of_moment_disp(self,exp_mat:np.ndarray,design_series:pd.Series):\n",
    "\n",
    "        v = self.trimmed_design_variance(np.array(exp_mat),design_series)\n",
    "\n",
    "        m = exp_mat.mean(axis=0)\n",
    "        alpha = (v - m) / m**2\n",
    "\n",
    "        # cannot use the typical min_disp = 1e-8 here or else all counts in the same\n",
    "        # group as the outlier count will get an extreme Cook's distance\n",
    "        min_disp = 0.04\n",
    "        np.maximum(alpha, min_disp, out=alpha)\n",
    "        return alpha\n",
    "\n",
    "    def calculate_cook_distance(self,exp_mat:pd.DataFrame, design_series:pd.Series):\n",
    "\n",
    "        outliers = {}\n",
    "\n",
    "        alphas = self.robust_method_of_moment_disp(np.array(exp_mat),design_series)\n",
    "        \n",
    "        genes = exp_mat.columns\n",
    "        exp_mat[design_series.name] = design_series\n",
    "\n",
    "        m = len(design_series)\n",
    "        p = len(design_series.unique()) + 1\n",
    "        f_cutoff = f.ppf(0.99, p, m - p)\n",
    "\n",
    "        shm_exp_mat, shared_exp_mat = self.initialize_shared_memory(exp_mat)\n",
    "\n",
    "        self.resource_monitor.start()\n",
    "\n",
    "        n_batches = (len(genes) + self.batch_size - 1) // self.batch_size\n",
    "        for i in range(n_batches):\n",
    "            gene_batch = genes[i * self.batch_size: (i + 1) * self.batch_size]\n",
    "            alpha_batch = alphas[i * self.batch_size: (i + 1) * self.batch_size]\n",
    "            #print(gene_batch)\n",
    "\n",
    "            with ProcessPoolExecutor(max_workers=self.n_cores) as executor:\n",
    "                futures = [executor.submit(self.gene_cook_distance, gene, alpha, exp_mat, design_series, f_cutoff) for gene, alpha in zip(gene_batch, alpha_batch)]\n",
    "\n",
    "                for future in as_completed(futures):\n",
    "                    result = future.result()\n",
    "                    if result:\n",
    "                        gene, outliers_index, cooks_d = result\n",
    "                        outliers[gene]=(outliers_index,cook_d)\n",
    "\n",
    "        self.resource_monitor.stop()\n",
    "\n",
    "        shm_exp_mat.close()\n",
    "        shm_exp_mat.unlink()\n",
    "\n",
    "        return outliers\n",
    "\n",
    "\n",
    "    def gene_cook_distance(self, gene, alpha, exp_mat, design_series, f_cutoff):\n",
    "\n",
    "        model = sm.glm(formula=f\"{gene} ~C({design_series.name})\", data=exp_mat[[gene, design_series.name]],family=sm.families.NegativeBinomial(alpha=1//alpha)).fit()\n",
    "        cooks_d = model.get_influence().cooks_distance[0]\n",
    "        outliers_index = np.where(cooks_d > f_cutoff)[0]\n",
    "        \n",
    "        return (gene, outliers_index, cooks_d) if len(outliers_index) > 0 else None\n",
    "        \n",
    "    @staticmethod   \n",
    "    def initialize_shared_memory(exp_mat):\n",
    "\n",
    "        shm_exp_mat = shared_memory.SharedMemory(create=True, size=exp_mat.values.nbytes)\n",
    "        shared_exp_mat = np.ndarray(exp_mat.shape, dtype=exp_mat.values.dtype, buffer=shm_exp_mat.buf)\n",
    "        np.copyto(shared_exp_mat, exp_mat.values)\n",
    "        return shm_exp_mat, shared_exp_mat\n",
    "\n",
    "    def start_resource_monitor(self):\n",
    "        stop_event = threading.Event()\n",
    "        monitor_thread = Thread(target=self.check_monitor_resources, args=stop_event)\n",
    "        monitor_thread.deamon = True\n",
    "        monitor_thread.start()\n",
    "\n",
    "        return stop_event\n",
    "\n",
    "    @staticmethod\n",
    "    def check_monitor_resources(stop_event):\n",
    "        while not stop_event.is_set() :\n",
    "            print(f\"RAM Usage: {psutil.virtual_memory().percent}% | CPU Usage: {psutil.cpu_percent()}%\")\n",
    "            time.sleep(1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9caa40d-c6d1-4bc6-a95b-b6fde5f2508d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM Usage: 75.6% | CPU Usage: 6.2%\n",
      "RAM Usage: 75.6% | CPU Usage: 6.2%\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot pickle '_thread.lock' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/thomas/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 244, in _feed\n    obj = _ForkingPickler.dumps(obj)\n  File \"/home/thomas/anaconda3/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\nTypeError: cannot pickle '_thread.lock' object\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m cookdistana\u001b[38;5;241m.\u001b[39mtrimmed_design_variance(exp_mat \u001b[38;5;241m=\u001b[39m counts, design_series \u001b[38;5;241m=\u001b[39m des)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#cookdistana.calculate_cook_distance(exp_mat=data.exp_mat.T,design_series=data.meta['Subtype'])\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mcookdistana\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_cook_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_mat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcounts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesign_series\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdes\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 97\u001b[0m, in \u001b[0;36mCookDistanceAnalyzer.calculate_cook_distance\u001b[0;34m(self, exp_mat, design_series)\u001b[0m\n\u001b[1;32m     94\u001b[0m futures \u001b[38;5;241m=\u001b[39m [executor\u001b[38;5;241m.\u001b[39msubmit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgene_cook_distance, gene, alpha, exp_mat, design_series, f_cutoff) \u001b[38;5;28;01mfor\u001b[39;00m gene, alpha \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(gene_batch, alpha_batch)]\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m as_completed(futures):\n\u001b[0;32m---> 97\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m     99\u001b[0m         gene, outliers_index, cooks_d \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/multiprocessing/queues.py:244\u001b[0m, in \u001b[0;36mQueue._feed\u001b[0;34m(buffer, notempty, send_bytes, writelock, reader_close, writer_close, ignore_epipe, onerror, queue_sem)\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# serialize the data before acquiring the lock\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wacquire \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    246\u001b[0m     send_bytes(obj)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/multiprocessing/reduction.py:51\u001b[0m, in \u001b[0;36mForkingPickler.dumps\u001b[0;34m(cls, obj, protocol)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdumps\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     50\u001b[0m     buf \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buf\u001b[38;5;241m.\u001b[39mgetbuffer()\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle '_thread.lock' object"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM Usage: 75.7% | CPU Usage: 18.4%\n",
      "RAM Usage: 75.7% | CPU Usage: 1.1%\n",
      "RAM Usage: 75.7% | CPU Usage: 2.1%\n",
      "RAM Usage: 75.4% | CPU Usage: 6.4%\n",
      "RAM Usage: 75.5% | CPU Usage: 11.9%\n",
      "RAM Usage: 75.5% | CPU Usage: 9.3%\n",
      "RAM Usage: 75.5% | CPU Usage: 10.7%\n",
      "RAM Usage: 75.5% | CPU Usage: 5.1%\n",
      "RAM Usage: 75.5% | CPU Usage: 2.8%\n",
      "RAM Usage: 75.4% | CPU Usage: 2.1%\n",
      "RAM Usage: 75.4% | CPU Usage: 3.1%\n",
      "RAM Usage: 75.4% | CPU Usage: 1.2%\n",
      "RAM Usage: 75.4% | CPU Usage: 2.1%\n",
      "RAM Usage: 75.3% | CPU Usage: 1.4%\n",
      "RAM Usage: 75.3% | CPU Usage: 7.5%\n",
      "RAM Usage: 75.4% | CPU Usage: 5.8%\n",
      "RAM Usage: 75.4% | CPU Usage: 7.2%\n",
      "RAM Usage: 75.4% | CPU Usage: 3.1%\n",
      "RAM Usage: 75.5% | CPU Usage: 5.9%\n",
      "RAM Usage: 75.4% | CPU Usage: 6.3%\n",
      "RAM Usage: 75.4% | CPU Usage: 5.8%\n",
      "RAM Usage: 75.4% | CPU Usage: 10.1%\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "cookdistana=CookDistanceAnalyzer()\n",
    "\n",
    "#for chunks in cookdistana.chunkify_exp_mat(exp_mat=np.array(data.exp_mat.T),design_series=data.meta['Subtype']):\n",
    "#    print(chunks[0])\n",
    "#    print(chunks[1])\n",
    "counts = copy.copy(data.exp_mat.T)\n",
    "des =  copy.copy(data.meta['Subtype'])\n",
    "cookdistana.trimmed_design_variance(exp_mat = counts, design_series = des)\n",
    "#cookdistana.calculate_cook_distance(exp_mat=data.exp_mat.T,design_series=data.meta['Subtype'])\n",
    "cookdistana.calculate_cook_distance(exp_mat = counts, design_series = des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d680d4c-6cd0-4d37-870e-6e3b48535fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM Usage: 70.1% | CPU Usage: 21.3%\n",
      "RAM Usage: 69.9% | CPU Usage: 5.3%\n",
      "RAM Usage: 69.6% | CPU Usage: 2.4%\n",
      "RAM Usage: 69.4% | CPU Usage: 2.5%\n",
      "RAM Usage: 69.1% | CPU Usage: 1.3%\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "class ResourceMonitor:\n",
    "    def __init__(self):\n",
    "        # Event to control when to stop the monitoring thread\n",
    "        self._stop_event = threading.Event()\n",
    "        self.monitor_thread = threading.Thread(target=self.monitor_resources, daemon=True)\n",
    "\n",
    "    def monitor_resources(self):\n",
    "        while not self._stop_event.is_set():\n",
    "            print(f\"RAM Usage: {psutil.virtual_memory().percent}% | CPU Usage: {psutil.cpu_percent()}%\")\n",
    "            time.sleep(1)\n",
    "\n",
    "    def start(self):\n",
    "        # Start the daemon thread\n",
    "        self.monitor_thread.start()\n",
    "\n",
    "    def stop(self):\n",
    "        # Signal the thread to stop and wait for it to finish\n",
    "        self._stop_event.set()\n",
    "        self.monitor_thread.join()  # Wait for the thread to terminate cleanly\n",
    "\n",
    "# Usage example:\n",
    "monitor = ResourceMonitor()\n",
    "monitor.start()\n",
    "\n",
    "# Main processing code goes here\n",
    "time.sleep(5)  # Simulate work\n",
    "\n",
    "# Stop the monitor when processing is done\n",
    "monitor.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0503b720-27f5-461f-9193-65e8ae38958f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

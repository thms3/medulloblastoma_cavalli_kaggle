


import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

#from scipy.stats import pearsonr  

from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler


path_data_prot_coding='/home/thomas/Documents/git/medulloblastoma_cavalli_kaggle/data/in/protein_coding/'
path_metadata_prot_coding = path_data_prot_coding + 'GSE85217_Cavalli_subgroups_information_protein_coding.csv'
path_exp_mat_prot_coding = path_data_prot_coding + 'GSE85217_M_exp_763_MB_SubtypeStudy_TaylorLab_protein_coding.csv'


exp_mat_prot_coding = pd.read_csv(path_exp_mat_prot_coding,index_col=0)
metadata_prot_coding = pd.read_csv(path_metadata_prot_coding,index_col=0)
#exp_mat_prot_coding=exp_mat_prot_coding[metadata_prot_coding.index.tolist()]


#exp_mat_prot_coding=exp_mat_prot_coding.T
#exp_mat_prot_coding=exp_mat_prot_coding.loc[metadata_prot_coding['Study_ID']]


exp_mat_prot_coding_dist = pd.concat([exp_mat_prot_coding.mean(axis=0),exp_mat_prot_coding.median(axis=0),exp_mat_prot_coding.std(axis=0)],axis=1)
exp_mat_prot_coding_dist.columns = ['mean','median','sd']
exp_mat_prot_coding_dist.sort_values(by=['mean','median','sd'],inplace=True)


exp_mat_prot_coding=exp_mat_prot_coding[exp_mat_prot_coding_dist.index.tolist()]
#exp_mat_prot_coding


# standard scaler
sc = StandardScaler()
exp_mat = sc.fit_transform(exp_mat_prot_coding)


# PCA
pca = PCA()
pca_embedded = pca.fit_transform(X=exp_mat)


exp_vars_ratio = np.cumsum(pca.explained_variance_ratio_)


pos_exp_vars_ratio = len([i for i in exp_vars_ratio if i <= 0.95])


fig, ax = plt.subplots(1,1,figsize=(6,6))
ax.plot(range(len(exp_vars_ratio)),exp_vars_ratio,linewidth=1)
ax.axvline(x=pos_exp_vars_ratio,c='black',linewidth=0.5, linestyle="dashed")
ax.axhline(y=exp_vars_ratio[pos_exp_vars_ratio],c='black',linewidth=0.5,linestyle="dashed")





pca_embedded_pc1_pc2=pd.DataFrame(data=pca_embedded[:,[0,1]], columns=['PC1','PC2'])
pca_embedded_pc1_pc2.shape
#pca_embedded_pc1_pc2.index = exp_mat_prot_coding.columns
#pca_embedded_pc1_pc2=pd.concat([pca_embedded_pc1_pc2,metadata_prot_coding['Subtype']],axis=1)


pca_embedded_pc1_pc2.index = exp_mat_prot_coding.index


pca_embedded_pc1_pc2['Subtype'] = metadata_prot_coding['Subtype']


pal_subtype={'WNT_alpha':'royalblue',
             'WNT_beta':'lightskyblue',
             'SHH_alpha':'crimson',
             'SHH_beta':'peru',
             'SHH_gamma':'orchid',
             'SHH_delta':'lightpink',
             'Group3_alpha':'gold',
             'Group3_beta':'khaki',
             'Group3_gamma':'orange',
             'Group4_gamma':'forestgreen',
             'Group4_beta':'palegreen',
             'Group4_alpha':'springgreen'}

fig, ax = plt.subplots(1,1,figsize=(6,6))
plt.axvline(x=0,c='black',linewidth=0.5, linestyle="dashed",zorder=1) # add zorder
plt.axhline(y=0,c='black',linewidth=0.5,linestyle="dashed",zorder=1) 
ax.set_axisbelow(True)
sns.scatterplot(data = pca_embedded_pc1_pc2, x='PC1', y='PC2', hue='Subtype', legend=False, ax=ax, palette=pal_subtype)
ax.set_xlabel("PC1 ({:.2f}%)".format(pca.explained_variance_ratio_[0]*100))
ax.set_ylabel("PC2 ({:.2f}%)".format(pca.explained_variance_ratio_[1]*100))

plt.savefig('pca_pc1_pc2.png')

plt.show()


from scipy.special import betainc

def optim_pearson(x,y):
    # Assumes inputs are DataFrames and computation is to be performed
    # pairwise between columns. We convert to arrays and reshape so calculation
    # is performed according to normal broadcasting rules along the last axis.
    x = np.asarray(x).T[:, np.newaxis, :]
    y = np.asarray(y).T
    n = x.shape[-1]

    # Compute Pearson correlation coefficient. We can't use `cov` or `corrcoef`
    # because they want to compute everything pairwise between rows of a
    # stacked x and y.
    xm = x.mean(axis=-1, keepdims=True)
    ym = y.mean(axis=-1, keepdims=True)
    cov = np.sum((x - xm) * (y - ym), axis=-1)/(n-1)
    sx = np.std(x, ddof=1, axis=-1)
    sy = np.std(y, ddof=1, axis=-1)
    rho = cov/(sx * sy)

    # Compute the two-sided p-values. See documentation of scipy.stats.pearsonr.
    ab = n/2 - 1
    x = (abs(rho) + 1)/2
    p = 2*(1-betainc(ab, ab, x))
    return rho, p


def gen_pairs_features(exp_mat,idx=0):
    for i in range(idx,exp_mat.shape[1]-1):
        yield idx,i+1


def remove_highly_corr_features(feat1,feat2,idx,rho_thresh=0.9):

    #rpval = pearsonr(feat1,feat2)
    rho = optim_pearson(feat1,feat2)

    if rho >= rho_thresh or -rho <= -rho_thresh :
        return idx
    else:
        return None


def chunkify_expr_mat(exp_mat,start=0,step=500):
    
    checkpoint = list(range(start,exp_mat.shape[1],step))+[exp_mat.shape[1]]
    
    for i in range(len(checkpoint)-1):
        yield checkpoint[i],checkpoint[i+1]


#for chunk in chunkify_expr_mat(exp_mat):
#    print(chunk)
chunk = (500,1000)
rho, p = optim_pearson(x=exp_mat[:,chunk[0]:chunk[1]],y=exp_mat[:,chunk[0]:chunk[1]])


def corr_select(rho,p,p_thresh=0.05,rho_thresh=0.9):

    p = np.where(p<=p_thresh,1,0)  
    #np.fill_diagonal(p,0)
    rho*=p
    
    return np.where(abs(rho) >= rho_thresh)


def fill_set_keep_and_set_remove(x,y,sx,sy,set_keep=None,set_remove=None):

    if set_keep is None:
        set_keep = set()
    if set_remove is None:
        set_remove = set()

    if len(x) != 0 and len(y) !=0:    
        for i,j in list(zip(x+sx,y+sy)):
            if i not in set_keep and j not in set_keep :
                if j in set_remove or  i in set_remove:
                    set_remove.update(set([i,j]))
                else :
                    set_keep.add(i)
                    set_remove.add(j)
            else :
                if i in set_keep:
                    set_remove.add(j)
                elif j in set_keep:
                    set_remove.add(i)
                    
    return set_keep,set_remove


chunks = [chunk for chunk in chunkify_expr_mat(exp_mat)]
chunks_array = np.array([[chunks[i],chunks[j]] for i in range(len(chunks)) for j in range(i,len(chunks))])


#toys_array = chunks_array[0:3]


#toys_array.shape[0]


p_thresh=0.05
rho_thresh=0.9

set_keep=set()
set_remove=set()
incr = int(chunks_array.shape[0]*0.05)

for i in range(chunks_array.shape[0]):

    load = int((i/chunks_array.shape[0])*100)
    
    if int(i)%incr == 0 :
        print(f"{load}%")
    
    chunk1=chunks_array[i][0]
    chunk2=chunks_array[i][1]

    rho, p = optim_pearson(x=exp_mat[:,chunk1[0]:chunk1[1]],y=exp_mat[:,chunk2[0]:chunk2[1]])
    
    p = np.where(p<=p_thresh,1,0)
    if (chunk1==chunk2).all():
        np.fill_diagonal(p,0)
    rho*=p

    idx = np.where(abs(rho) >= rho_thresh)

    set_keep,set_remove=fill_set_keep_and_set_remove(x=idx[0],y=idx[1],sx=chunk1[0],sy=chunk2[0],set_keep=set_keep,set_remove=set_remove)     


columns=[exp_mat_prot_coding.columns[i] for i in set_remove]


exp_mat_prot_coding_nocorr=exp_mat_prot_coding.drop(columns=[exp_mat_prot_coding.columns[i] for i in set_remove],axis=1)


exp_mat_prot_coding_nocorr.to_csv(path_data_prot_coding + 'GSE85217_M_exp_763_MB_SubtypeStudy_TaylorLab_protein_coding_nocorr.csv')


t = False


%%time
if t:
    for i,pair in enumerate(gen_pairs_features(exp_mat,idx=1)):
        if i%1000 == 0:
            print(i)
        corr_pair = remove_highly_corr_features(feat1=exp_mat[:,pair[0]],feat2=exp_mat[:,pair[1]],idx=pair[1])
        if corr_pair is not None:
            print(corr_pair)


%%time
if t:
    from concurrent.futures import ProcessPoolExecutor, as_completed
    idx=0
    while idx < exp_mat.shape[1]:
        if idx%100 == 0:
            print(idx)
        with ProcessPoolExecutor(max_workers=8) as executor:
            corr_feats = []
            futures = [executor.submit(remove_highly_corr_features,feat1=exp_mat[:,pair[0]],feat2=exp_mat[:,pair[1]],idx=pair[1]) for i,pair in enumerate(gen_pairs_features(exp_mat,idx=idx))]
            for future in as_completed(futures):
                result = future.result()
                if result is not None:
                    corr_feats.append(result)
        
            if len(corr_feats)>0:
                np.delete(exp_mat,corr_feats)
                print(corr_feats)
                print(exp_mat.shape)
            idx+=1
        







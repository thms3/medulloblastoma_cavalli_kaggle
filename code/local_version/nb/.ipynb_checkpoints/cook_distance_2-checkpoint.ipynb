{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8ec6823-d6cb-42ed-9d12-4f66f931f590",
   "metadata": {},
   "source": [
    "# [GSE85217] Tracking outliers - Cook's Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b65d5003-3944-40b8-868b-e5953a59c18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m[C 2024-11-05 16:48:01.443 ServerApp]\u001b[m No such file or directory: /home/thomas/Documents/git/medulloblastoma_cavalli_kaggle/code/local_version/nb/enable\n"
     ]
    }
   ],
   "source": [
    "!jupyter-lab enable widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9443b5-8101-4610-b4b4-62bab2e4f293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 16:48:07.898640: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-05 16:48:07.987992: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-05 16:48:08.014982: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-05 16:48:08.152004: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-05 16:48:09.564687: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# lib\n",
    "#import modin.pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import umap\n",
    "\n",
    "# fig\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# local lib\n",
    "import sys\n",
    "sys.path.insert(1,'/home/thomas/Documents/git/medulloblastoma_cavalli_kaggle/code/local_version/fun')\n",
    "\n",
    "from parser import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bd985d0-b751-4866-bd34-f99827540ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3cf2390-024e-4acd-84fc-5bfed7eff211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f\n",
    "from statsmodels.formula.api import glm\n",
    "import statsmodels.api as sm\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "115e2d16-0f80-4b98-abc2-79daeccee0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data='/home/thomas/Documents/git/medulloblastoma_cavalli_kaggle/data/in/'\n",
    "path_exp_mat = path_data + 'GSE85217_M_exp_763_MB_SubtypeStudy_TaylorLab_parsed.txt'\n",
    "path_meta = path_data + 'GSE85217_Cavalli_subgroups_information_parsed.csv'\n",
    "\n",
    "data=Data()\n",
    "data.add_exp_mat(path_exp_mat,index_col=\"genes_name\")\n",
    "data.add_meta(path_meta=path_meta,index_col=\"samples_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a8c11e8-d810-4227-8930-49339d313267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import f\n",
    "from statsmodels.formula.api import glm\n",
    "import statsmodels.api as sm\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from multiprocessing import shared_memory\n",
    "import psutil\n",
    "import time\n",
    "from threading import Thread\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3844ae32-91a7-41ca-ac2b-be333e9c163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "729eda52-f7a7-42de-ad57-1adab6908100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM Usage: 46.9% | CPU Usage: 30.0%\n",
      "RAM Usage: 47.1% | CPU Usage: 16.3%\n",
      "RAM Usage: 47.3% | CPU Usage: 14.4%\n",
      "RAM Usage: 47.1% | CPU Usage: 13.5%\n",
      "RAM Usage: 47.1% | CPU Usage: 13.0%\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "class ResourceMonitor:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.stop_event = threading.Event()\n",
    "        self.monitor_thread = threading.Thread(target=self.monitor_resources)\n",
    "        self.monitor_thread.deamon = True\n",
    "\n",
    "    def monitor_resources(self):\n",
    "        while not self.stop_event.is_set():\n",
    "            print(f\"RAM Usage: {psutil.virtual_memory().percent}% | CPU Usage: {psutil.cpu_percent()}%\")\n",
    "            time.sleep(1)\n",
    "\n",
    "    def start(self):\n",
    "        # Start the deamon thread\n",
    "        self.monitor_thread.start()\n",
    "\n",
    "    def stop(self):\n",
    "        # Signal the thread to stop and wait for it to finish\n",
    "        self.stop_event.set()\n",
    "        self.monitor_thread.join()\n",
    "\n",
    "    \n",
    "# Usage example:\n",
    "monitor = ResourceMonitor()\n",
    "monitor.start()\n",
    "\n",
    "# Main processing code goes here\n",
    "time.sleep(5)  # Simulate work\n",
    "\n",
    "# Stop the monitor when processing is done\n",
    "monitor.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3d31ddb-3b56-4153-903d-1e7b35dccfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CookDistanceAnalyzer:\n",
    "\n",
    "    def __init__(self, n_cores=6, batch_size = 100):\n",
    "        self.n_cores = n_cores\n",
    "        self.batch_size = batch_size\n",
    "        self.resource_monitor = ResourceMonitor()\n",
    "        \n",
    "    @staticmethod\n",
    "    def _print_mp(text):\n",
    "        print(text)\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "    @classmethod\n",
    "    def worker_mp(cls,job_id:int,worker,**kwargs):\n",
    "        cls._print_mp(\"Processing chunk: \"+str(job))\n",
    "        output = worker(**kwargs)\n",
    "        cls._print_mp(\"Finished chunk: \"+str(job))\n",
    "        return output\n",
    "        \n",
    "    @staticmethod\n",
    "    def trimfn(x: float) -> int:\n",
    "        return 2 if x >= 23.5 else 1 if x >= 3.5 else 0\n",
    "\n",
    "    @staticmethod\n",
    "    def trimmed_mean(x: np.ndarray, trim: float = 0.1, **kwargs) -> np.ndarray:\n",
    "    \n",
    "        assert trim <= 0.5\n",
    "    \n",
    "        kwargs.setdefault('axis',0)\n",
    "        \n",
    "        axis = kwargs.get(\"axis\")\n",
    "        s = np.sort(x,**kwargs)\n",
    "        n = x.shape[axis]\n",
    "        ntrim = math.floor(n * trim)\n",
    "        return np.take(s, np.arange(ntrim, n - ntrim), axis).mean(**kwargs)\n",
    "\n",
    "    def chunkify_exp_mat(self,exp_mat,design_series):\n",
    "\n",
    "            ns = design_series.value_counts()\n",
    "            trimratio = (1 / 3, 1 / 4, 1 / 8)\n",
    "\n",
    "            for var in design_series.unique():\n",
    "                lvl = self.trimfn(ns[var])\n",
    "                yield exp_mat[design_series == var, :], lvl\n",
    "\n",
    "    def trimmed_design_variance(self, exp_mat: np.ndarray, design_series: pd.Series) -> np.ndarray:\n",
    "        return np.array([self.process_variance(exp_mat,lvl) for exp_mat,lvl in self.chunkify_exp_mat(np.array(exp_mat),design_series)]).mean(0)\n",
    "            \n",
    "            \n",
    "    def process_variance(self,exp_mat:np.ndarray,lvl:int,trim_ratio=(1 / 3, 1 / 4, 1 / 8),scale=[2.04, 1.86, 1.51]):\n",
    "        var_means = self.trimmed_mean(x=exp_mat, trim=trim_ratio[lvl], axis = 0)\n",
    "        sqerror_var = (exp_mat - var_means) ** 2\n",
    "        variance_means = self.trimmed_mean(sqerror_var, trim=trim_ratio[lvl], axis=0)\n",
    "        variance_means*=scale[lvl]\n",
    "        return variance_means\n",
    "\n",
    "    def robust_method_of_moment_disp(self,exp_mat:np.ndarray,design_series:pd.Series):\n",
    "\n",
    "        v = self.trimmed_design_variance(np.array(exp_mat),design_series)\n",
    "\n",
    "        m = exp_mat.mean(axis=0)\n",
    "        alpha = (v - m) / m**2\n",
    "\n",
    "        # cannot use the typical min_disp = 1e-8 here or else all counts in the same\n",
    "        # group as the outlier count will get an extreme Cook's distance\n",
    "        min_disp = 0.04\n",
    "        np.maximum(alpha, min_disp, out=alpha)\n",
    "        return alpha\n",
    "\n",
    "    def calculate_cook_distance(self,exp_mat:pd.DataFrame, design_series:pd.Series) -> dict:\n",
    "\n",
    "        outliers = {}\n",
    "\n",
    "        alphas = self.robust_method_of_moment_disp(np.array(exp_mat),design_series)\n",
    "        #genes = exp_mat.columns\n",
    "        #exp_mat[design_series.name] = design_series\n",
    "\n",
    "        #m = len(design_series)\n",
    "        #p = len(design_series.unique()) + 1\n",
    "        #f_cutoff = f.ppf(0.99, p, m - p)\n",
    "\n",
    "        #shm_exp_mat, shared_exp_mat = self.initialize_shared_memory(exp_mat)\n",
    "\n",
    "        self.resource_monitor.start()\n",
    "\n",
    "        #n_batches = (len(genes) + self.batch_size - 1) // self.batch_size\n",
    "        #for i in range(n_batches):\n",
    "        #    gene_batch = gene[i * self.batch_size: (i + 1) * self.batch_size]\n",
    "        #    alpha_batch = alphas[i * self.batch_size: (i + 1) * self.batch_size]\n",
    "\n",
    "         #   with ProcessPoolExecutor(max_workers=self.n_cores) as executor:\n",
    "          #      futures = [executor.submit(self.gene_cook_distance, gene, alpha, exp_mat, design_series, f_cutoff) for gene, alpha in zip(gene_batch, alpha_batch)]\n",
    "\n",
    "           #     for future in as_completed(futures):\n",
    "            #        result = future.result()\n",
    "             #       if result:\n",
    "              #          gene, outliers_index, cooks_d = result\n",
    "               #         outliers[gene]=(outliers_index,cook_d)\n",
    "\n",
    "        \n",
    "        #shm_exp_mat.close()\n",
    "        #shm_exp_mat.unlink()\n",
    "\n",
    "        return alphas\n",
    "\n",
    "\n",
    "    def gene_cook_distance(self, gene, alpha, exp_mat, design_series, f_cutoff):\n",
    "\n",
    "        model = sm.glm(formula=f\"{gene} ~C({design_series.name})\", data=exp_mat[[gene, design_series.name]],family=sm.families.NegativeBinomial(alpha=1//alpha)).fit()\n",
    "        cooks_d = model.get_influence().cooks_distance[0]\n",
    "        outliers_index = np.where(cooks_d > f_cutoff)[0]\n",
    "        \n",
    "        return (gene, outliers_index, cooks_d) if len(outliers_index) > 0 else None\n",
    "        \n",
    "    @staticmethod   \n",
    "    def initialize_shared_memory(exp_mat):\n",
    "\n",
    "        shm_exp_mat = shared_memory.SharedMemory(create=True, size=exp_mat.values.nbytes)\n",
    "        shared_exp_mat = np.ndarray(exp_mat.shape, dtype=exp_mat.values.dtype, buffer=shm_exp_mat.buf)\n",
    "        np.copyto(shared_exp_mat, exp_mat.values)\n",
    "        return shm_exp_mat, shared_exp_mat\n",
    "\n",
    "    def start_resource_monitor(self):\n",
    "        stop_event = threading.Event()\n",
    "        monitor_thread = Thread(target=self.check_monitor_resources, args=stop_event)\n",
    "        monitor_thread.deamon = True\n",
    "        monitor_thread.start()\n",
    "\n",
    "        return stop_event\n",
    "\n",
    "    @staticmethod\n",
    "    def check_monitor_resources(stop_event):\n",
    "        while not stop_event.is_set() :\n",
    "            print(f\"RAM Usage: {psutil.virtual_memory().percent}% | CPU Usage: {psutil.cpu_percent()}%\")\n",
    "            time.sleep(1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9caa40d-c6d1-4bc6-a95b-b6fde5f2508d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24281818, 0.0417125 , 0.10444555, ..., 0.14860632, 0.44211168,\n",
       "       0.04032336])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "cookdistana=CookDistanceAnalyzer()\n",
    "\n",
    "#for chunks in cookdistana.chunkify_exp_mat(exp_mat=np.array(data.exp_mat.T),design_series=data.meta['Subtype']):\n",
    "#    print(chunks[0])\n",
    "#    print(chunks[1])\n",
    "counts = copy.copy(data.exp_mat.T)\n",
    "des =  copy.copy(data.meta['Subtype'])\n",
    "cookdistana.trimmed_design_variance(exp_mat = counts, design_series = des)\n",
    "#cookdistana.calculate_cook_distance(exp_mat=data.exp_mat.T,design_series=data.meta['Subtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d680d4c-6cd0-4d37-870e-6e3b48535fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "class ResourceMonitor:\n",
    "    def __init__(self):\n",
    "        # Event to control when to stop the monitoring thread\n",
    "        self._stop_event = threading.Event()\n",
    "        self.monitor_thread = threading.Thread(target=self.monitor_resources, daemon=True)\n",
    "\n",
    "    def monitor_resources(self):\n",
    "        while not self._stop_event.is_set():\n",
    "            print(f\"RAM Usage: {psutil.virtual_memory().percent}% | CPU Usage: {psutil.cpu_percent()}%\")\n",
    "            time.sleep(1)\n",
    "\n",
    "    def start(self):\n",
    "        # Start the daemon thread\n",
    "        self.monitor_thread.start()\n",
    "\n",
    "    def stop(self):\n",
    "        # Signal the thread to stop and wait for it to finish\n",
    "        self._stop_event.set()\n",
    "        self.monitor_thread.join()  # Wait for the thread to terminate cleanly\n",
    "\n",
    "# Usage example:\n",
    "monitor = ResourceMonitor()\n",
    "monitor.start()\n",
    "\n",
    "# Main processing code goes here\n",
    "time.sleep(5)  # Simulate work\n",
    "\n",
    "# Stop the monitor when processing is done\n",
    "monitor.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0503b720-27f5-461f-9193-65e8ae38958f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

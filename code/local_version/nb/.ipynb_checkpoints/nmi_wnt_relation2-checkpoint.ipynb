{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02b20ffa-320b-4ba3-9677-08dc59363666",
   "metadata": {},
   "source": [
    "# Non linear relation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a26a62bf-8294-41e4-9d32-3269a93a3d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "\n",
    "import heapq\n",
    "\n",
    "import scipy as sp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.special import betainc\n",
    "\n",
    "import numba \n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d76dbbb4-9ee1-4c62-ae60-0b9f8cf0d581",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c73251c-4d31-4068-9b87-a104d6e35e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cross_tt = '/home/thomas/Documents/git/medulloblastoma_cavalli_kaggle/data/dge/cross_tt_genes_wnt_vs_all.csv'\n",
    "path_adj_mat_pearson_wnt = '/home/thomas/Documents/git/medulloblastoma_cavalli_kaggle/data/network/adj_mat_pearson_wnt_target_mannwhitneyu.csv'\n",
    "path_adj_mat_pearson = '/home/thomas/Documents/git/medulloblastoma_cavalli_kaggle/data/network/adj_mat_pearson.csv'\n",
    "path_expr_mat='/home/thomas/Documents/git/medulloblastoma_cavalli_kaggle/data/in/protein_coding/GSE85217_M_exp_763_MB_SubtypeStudy_TaylorLab_protein_coding.csv'\n",
    "path_metadata = '/home/thomas/Documents/git/medulloblastoma_cavalli_kaggle/data/in/protein_coding/GSE85217_Cavalli_subgroups_information_protein_coding.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d614d51b-db16-47be-8a75-ce27261ea266",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mat_pearson_wnt = pd.read_csv(path_adj_mat_pearson_wnt,index_col=0)\n",
    "cross_tt=pd.read_csv(path_cross_tt,index_col=0)\n",
    "expr_mat = pd.read_csv(path_expr_mat,index_col=0)\n",
    "metadata = pd.read_csv(path_metadata,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83abdc0c-80b0-426c-873f-08645b362408",
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_mat_wnt = expr_mat.loc[metadata[metadata['Subgroup']=='WNT']['Study_ID'].to_list(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ccc553b-5697-410d-9f90-a48271e6c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_corr_mat = adj_mat_pearson_wnt.columns.tolist()\n",
    "genes_wnt_dge=cross_tt[cross_tt['all']==1].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "596ebc4a-b536-46c0-9566-350c00075e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_mat_wnt_genes = expr_mat_wnt[list(set(genes_wnt_dge + genes_corr_mat))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29b5907d-c689-431a-88c3-e267027c6f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the data \n",
    "sc = StandardScaler()\n",
    "expr_mat_wnt_sc = sc.fit_transform(expr_mat_wnt_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "921a1b96-f39a-433a-b756-56b9a2c3474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimmed_mean(expr_mat,threshold=0.05):\n",
    "\n",
    "    t_index=int(np.floor(expr_mat.shape[0]*(threshold/2)))\n",
    "\n",
    "    trim_expr_mat=np.zeros((expr_mat.shape[0]-(2*t_index),expr_mat.shape[1]))\n",
    "\n",
    "    for i in range(expr_mat.shape[1]):\n",
    "        trim_expr_mat[:,i]=expr_mat[:,i][t_index:-t_index]\n",
    "\n",
    "    return trim_expr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39ff59e0-14a9-44df-8604-0f7609c68035",
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_mat_wnt_trim=trimmed_mean(expr_mat_wnt_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abb73f79-052f-44e7-b247-5d22d71814bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "class ResourceMonitor:\n",
    "    def __init__(self,t_sleep=1):\n",
    "        # Event to control when to stop the monitoring thread\n",
    "        self._stop_event = threading.Event()\n",
    "        self.monitor_thread = threading.Thread(target=self.monitor_resources, daemon=True)\n",
    "        self.t_sleep=t_sleep\n",
    "\n",
    "    def monitor_resources(self):\n",
    "        while not self._stop_event.is_set():\n",
    "            print(f\"RAM Usage: {psutil.virtual_memory().percent}% | CPU Usage: {psutil.cpu_percent()}%\")\n",
    "            time.sleep(self.t_sleep)\n",
    "\n",
    "    def start(self):\n",
    "        # Start the daemon thread\n",
    "        self.monitor_thread.start()\n",
    "\n",
    "    def stop(self):\n",
    "        # Signal the thread to stop and wait for it to finish\n",
    "        self._stop_event.set()\n",
    "        self.monitor_thread.join()  # Wait for the thread to terminate cleanly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "318b2f35-f99d-437d-adb9-9b2a48af46d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_xy_to_grid(x:np.ndarray,y:np.ndarray,gridsize=(200,200),extents=None):\n",
    "\n",
    "    if extents is None:\n",
    "        xmin = x.min(axis=0)\n",
    "        xmax = x.max(axis=0)\n",
    "        ymin = y.min(axis=0)\n",
    "        ymax = y.max(axis=0)\n",
    "    else : \n",
    "        xmin, xmax, ymin, ymax = map(np.ndarray, extents)\n",
    "\n",
    "    dx = (xmax - xmin) / (gridsize[0] - 1)\n",
    "    dy = (ymax - ymin) / (gridsize[1] - 1)\n",
    "\n",
    "    xmin = xmin.reshape(1,-1)\n",
    "    ymin = ymin.reshape(1,-1)\n",
    "\n",
    "    dx = dx.reshape(1,-1)\n",
    "    dy = dy.reshape(1,-1)\n",
    "\n",
    "    # Adjust x and y to pixel coordinates inplace\n",
    "    x_pix = np.floor((x - xmin) / dx)\n",
    "    y_pix = np.floor((y - ymin) / dy)\n",
    "    \n",
    "    return x_pix, y_pix, list(dx[0,:]), list(dx[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "350a1914-bb33-4349-845c-75f4401518c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_vars(x,y,nocorr=True):\n",
    "\n",
    "    x = np.asarray(x).T[:, np.newaxis, :]\n",
    "    y = np.asarray(y).T\n",
    "    n = x.shape[-1]\n",
    "\n",
    "\n",
    "\n",
    "    xm = x.mean(axis=-1, keepdims=True)\n",
    "    ym = y.mean(axis=-1, keepdims=True)\n",
    "\n",
    "    cov = np.sum((x - xm) * (y - ym), axis=-1)/(n-1)\n",
    "\n",
    "    std_x = np.std(x, ddof=1, axis=-1)\n",
    "    std_y = np.std(y, ddof=1, axis=-1)\n",
    "\n",
    "    if nocorr:\n",
    "        np.fill_diagonal(cov,0)\n",
    "        \n",
    "    return cov, std_x**2, std_y**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e7d3eec-98ff-4255-a5e1-5cc08a6a9386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkify_expr_mat(expr_mat,start=0,step=10):\n",
    "    \n",
    "    chunk_points = list(range(start,expr_mat.shape[1],step))+[expr_mat.shape[1]]\n",
    "    \n",
    "    for i in range(len(chunk_points)-1):\n",
    "        yield chunk_points[i],chunk_points[i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "827987ae-91dd-41ec-9b91-5c27818ec0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triu_chunks(expr_mat,start=0,step=5):\n",
    "    \n",
    "    chunks = [chunk for chunk in chunkify_expr_mat(expr_mat=expr_mat,start=start,step=step)]\n",
    "\n",
    "    #for i,j in zip(*np.triu_indices(n=len(chunks))):\n",
    "    for i in range(len(chunks)):\n",
    "        for j in range(len(chunks)):\n",
    "            yield chunks[i], chunks[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dea285c8-954e-4a8a-8fba-f304d80902e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_chunks(chunks):\n",
    "\n",
    "    len_chunks0 = int(chunks[0][1])-int(chunks[0][0])\n",
    "    len_chunks1 = int(chunks[1][1])-int(chunks[1][0])\n",
    "\n",
    "    \n",
    "    if chunks[0] == chunks[1]:\n",
    "        for i in range(len_chunks0):\n",
    "            for j in range(i,len_chunks1):                \n",
    "                yield i,j\n",
    "    else :\n",
    "        for i in range(len_chunks0):\n",
    "            for j in range(len_chunks1):\n",
    "                yield i,j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b499f18-f4a2-4617-9ac1-934c346df643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_entropies(data,gridsize=(200,200),epsilon=1e-100):\n",
    "\n",
    "    kde_2d = np.zeros((data.shape[-1],data.shape[-1],gridsize[0],gridsize[1]))\n",
    "    for i in range(data.shape[1]):\n",
    "        for j in range(data.shape[1]):\n",
    "            kde_2d[i,j]=fast_kde(x=data[:,i],y=data[:,j], gridsize=gridsize,density=True)\n",
    "    probs = (kde_2d/data.shape[0]) + epsilon\n",
    "    joint_entropies = -(probs * np.log2(probs)).sum((2,3))\n",
    "    return joint_entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f4b9ffc-8ed5-49d5-aa56-fa86c57eafa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_kde(x,y, gridsize=(200,200), density = True, extents=None, nocorrelation=True, weights=None, cov=None):\n",
    "\n",
    "    # SETUP\n",
    "    x = np.squeeze((np.asarray(x)))\n",
    "    y = np.squeeze((np.asarray(y)))\n",
    "\n",
    "    if x.size != y.size:\n",
    "        raise ValueError('Input x & y arrays must be the same size!')\n",
    "\n",
    "    n = x.size\n",
    "\n",
    "    if weights is None:\n",
    "        # Default: Weight all points equally\n",
    "        weights = np.ones(n)\n",
    "    else:\n",
    "        weights = np.squeeze(np.asarray(weights))\n",
    "        if weights.size != x.size:\n",
    "            raise ValueError('Input weights must be an array of the same size'\n",
    "                    ' as input x & y arrays!')\n",
    "\n",
    "    if extents is None:\n",
    "        xmin=x.min()\n",
    "        xmax=x.max()\n",
    "        ymin=y.min()\n",
    "        ymax=y.max()\n",
    "    else :\n",
    "        xmin, xmax, ymin, ymax = map(float, extents)\n",
    "\n",
    "    dx = (xmax - xmin) / (gridsize[0] - 1)\n",
    "    dy = (ymax - ymin) / (gridsize[1] - 1)\n",
    "\n",
    "    # PRELIMINARY CALCULATIONS\n",
    "\n",
    "    # First convert x & y over to pixel coordinates\n",
    "    # (Avoiding np.digitize due to excessive memory usage!)\n",
    "    \n",
    "    # Adjust x and y to pixel coordinates inplace\n",
    "    x_pixel = np.floor((x - xmin) / dx)\n",
    "    y_pixel = np.floor((y - ymin) / dy)\n",
    "\n",
    "    # Stack the results after adjustment\n",
    "    xyi = np.vstack((x_pixel, y_pixel))\n",
    "\n",
    "    # Next, make a 2D histogram of x & y\n",
    "    # Avoiding np.histogram2d due to excessive memory usage with many points\n",
    "    grid = sp.sparse.coo_matrix((weights, xyi), shape=(gridsize)).toarray()\n",
    "\n",
    "    if cov is None:\n",
    "        cov = np.cov(xyi)\n",
    "\n",
    "    if nocorrelation:\n",
    "        cov[1, 0] = 0\n",
    "        cov[0, 1] = 0\n",
    "\n",
    "    # Scaling factor for bandwidth\n",
    "    scotts_factor = np.power(n, -1.0 / 6) # For 2D\n",
    "\n",
    "    # MAKE THE GAUSSIAN KERNEL\n",
    "\n",
    "    # First, determine how big the kernel needs to be\n",
    "    std_devs = np.diag(np.sqrt(cov))\n",
    "    kern_nx, kern_ny = np.round(scotts_factor * 2 * np.pi * std_devs)\n",
    " \n",
    "    # Determine the bandwidth to use for the gaussian kernel\n",
    "    inv_cov = np.linalg.inv(cov * scotts_factor**2) \n",
    " \n",
    "    # x & y (pixel) coords of the kernel grid, with <x,y> = <0,0> in center\n",
    "    xx = np.arange(kern_nx) - kern_nx / 2.0\n",
    "    yy = np.arange(kern_ny) - kern_ny / 2.0\n",
    "    xx, yy = np.meshgrid(xx, yy)\n",
    " \n",
    "    # Then evaluate the gaussian function on the kernel grid\n",
    "    kernel = np.vstack((xx.flatten(), yy.flatten()))\n",
    "    kernel = np.dot(inv_cov, kernel) * kernel\n",
    "    kernel = np.sum(kernel, axis=0) / 2.0\n",
    "    kernel = np.exp(-kernel).reshape(np.int64(kern_ny), np.int64(kern_nx))\n",
    "\n",
    "    # THE KERNEL DENSITY ESTIMATE\n",
    "\n",
    "    # Convolve the gaussian kernel with the 2D histogram, producing a gaussian\n",
    "    # kernel density estimate on a regular grid\n",
    "    #grid = sp.signal.convolve2d(grid, kernel, mode='same', boundary='fill').T\n",
    "    grid = sp.signal.fftconvolve(grid, kernel, mode='same').T\n",
    "    \n",
    "    # Normalization factor to divide result by so that units are in the same\n",
    "    # units as scipy.stats.kde.gaussian_kde's output.  \n",
    "    #norm_factor = 2 * np.pi * cov * scotts_factor**2\n",
    "    #norm_factor = np.linalg.det(norm_factor)\n",
    "    #norm_factor = n * dx * dy * np.sqrt(norm_factor)\n",
    "    det = np.linalg.det(cov)\n",
    "    if det < 0 :\n",
    "        sqrt_det = -np.sqrt(det)\n",
    "    else :\n",
    "        sqrt_det = np.sqrt(det)\n",
    "    \n",
    "    norm_factor = n * dx * dy * (2 * np.pi) * scotts_factor**2 * sqrt_det\n",
    "\n",
    " \n",
    "    # Normalize the result\n",
    "    grid /= norm_factor\n",
    "\n",
    "    grid +=abs(grid.min())\n",
    "\n",
    "    if density:\n",
    "        grid /=np.sum(grid)\n",
    "\n",
    "    return np.flipud(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b6f1939-79de-47fb-a02b-70f55aa66e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_entropies_x_y(x,y,gridsize=(200,200),epsilon=1e-100):\n",
    "\n",
    "    kde_2d = np.zeros((x.shape[-1],y.shape[-1],gridsize[0],gridsize[1]))\n",
    "    for i in range(x.shape[-1]):\n",
    "        for j in range(y.shape[-1]):\n",
    "            kde_2d[i,j]=fast_kde(x=x[:,i],y=y[:,j],gridsize=gridsize,density=False)\n",
    "            \n",
    "                \n",
    "    probs = kde_2d + epsilon\n",
    "    joint_entropies = -(probs * np.log2(probs)).sum((2,3))\n",
    "    return joint_entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "176073cd-3a4d-4ab9-b435-aedb1ca27b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_compute_mi_mat(expr_mat,step=5,epsilon=1e-10,gridsize=(200,200),t_sleep=1):\n",
    "\n",
    "    adj_mat = np.zeros((expr_mat.shape[1],expr_mat.shape[1]))\n",
    "\n",
    "    monitor = ResourceMonitor(t_sleep)\n",
    "    monitor.start()\n",
    "\n",
    "    results_dict={}\n",
    "    with ProcessPoolExecutor(max_workers=8) as executor:\n",
    "        futures = {executor.submit(batch_mi,expr_mat[:,chunk1[0]:chunk1[1]],expr_mat[:,chunk2[0]:chunk2[1]],gridsize,epsilon,k):np.array([chunk1,chunk2]) for chunk1, chunk2, k in all_chunks(expr_mat=expr_mat,step=step)}\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            chunks = futures[future]\n",
    "\n",
    "            try:\n",
    "                adj_mat[chunks[0][0]:chunks[0][1],chunks[1][0]:chunks[1][1]]=future.result()\n",
    "            except Exception as e:\n",
    "                print(f\"Error in processing {chunks}: {e}\")\n",
    "\n",
    "    monitor.stop()\n",
    "    return adj_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84acb682-1fee-4597-8a20-42a290bb0034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_joint_entropy(expr_mat,step=5,epsilon=1e-100,gridsize=(100,100),t_sleep=1):\n",
    "\n",
    "    joint_entropy_mat = np.zeros((expr_mat.shape[1],expr_mat.shape[1]))\n",
    "\n",
    "    monitor = ResourceMonitor(t_sleep)\n",
    "    monitor.start()\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=8) as executor:\n",
    "        futures = {executor.submit(joint_entropies_x_y,expr_mat[:,chunk1[0]:chunk1[1]],expr_mat[:,chunk2[0]:chunk2[1]],gridsize,epsilon):np.array([chunk1,chunk2]) for chunk1, chunk2 in triu_chunks(expr_mat,start=0,step=5)}\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            chunks = futures[future]\n",
    "\n",
    "            try:\n",
    "                joint_entropy_mat[chunks[0][0]:chunks[0][1],chunks[1][0]:chunks[1][1]]=future.result()\n",
    "            except Exception as e:\n",
    "                print(f\"Error in processing {chunks}: {e}\")\n",
    "\n",
    "    monitor.stop()\n",
    "\n",
    "    #joint_entropy_mat+=np.triu(joint_entropy_mat,k=1).T\n",
    "    return joint_entropy_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "224a7bdd-abf2-442f-b62a-7a426c696a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM Usage: 77.2% | CPU Usage: 19.1%\n",
      "RAM Usage: 82.2% | CPU Usage: 91.8%\n",
      "RAM Usage: 82.7% | CPU Usage: 100.0%\n",
      "RAM Usage: 82.8% | CPU Usage: 100.0%\n",
      "RAM Usage: 83.0% | CPU Usage: 100.0%\n",
      "RAM Usage: 83.0% | CPU Usage: 100.0%\n",
      "RAM Usage: 82.8% | CPU Usage: 100.0%\n",
      "RAM Usage: 82.8% | CPU Usage: 100.0%\n",
      "RAM Usage: 82.9% | CPU Usage: 100.0%\n",
      "RAM Usage: 82.8% | CPU Usage: 100.0%\n",
      "RAM Usage: 82.7% | CPU Usage: 100.0%\n",
      "RAM Usage: 82.8% | CPU Usage: 100.0%\n",
      "RAM Usage: 82.7% | CPU Usage: 100.0%\n",
      "RAM Usage: 82.7% | CPU Usage: 100.0%\n",
      "RAM Usage: 82.7% | CPU Usage: 100.0%\n",
      "RAM Usage: 82.8% | CPU Usage: 100.0%\n",
      "RAM Usage: 82.8% | CPU Usage: 100.0%\n",
      "RAM Usage: 83.2% | CPU Usage: 100.0%\n",
      "RAM Usage: 83.0% | CPU Usage: 100.0%\n",
      "RAM Usage: 83.0% | CPU Usage: 100.0%\n",
      "RAM Usage: 83.0% | CPU Usage: 100.0%\n",
      "RAM Usage: 83.1% | CPU Usage: 100.0%\n",
      "RAM Usage: 83.3% | CPU Usage: 100.0%\n",
      "RAM Usage: 83.2% | CPU Usage: 100.0%\n",
      "RAM Usage: 83.2% | CPU Usage: 100.0%\n",
      "RAM Usage: 83.1% | CPU Usage: 100.0%\n",
      "RAM Usage: 83.1% | CPU Usage: 100.0%\n",
      "RAM Usage: 83.2% | CPU Usage: 100.0%\n",
      "RAM Usage: 81.8% | CPU Usage: 100.0%\n",
      "RAM Usage: 81.9% | CPU Usage: 100.0%\n",
      "RAM Usage: 81.8% | CPU Usage: 100.0%\n"
     ]
    }
   ],
   "source": [
    "joint_entropy_mat = pool_joint_entropy(expr_mat_wnt_trim,step=5,epsilon=1e-10,gridsize=(200,200),t_sleep=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "694b6d59-22a5-4b81-967d-157837bcc1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5872.44565782, 5796.41681832, 6311.55171945, ..., 5170.08339662,\n",
       "        7519.22038154, 6039.28713657],\n",
       "       [5796.41681832, 4050.35506504, 5238.02988664, ..., 4276.66916473,\n",
       "        6153.95870759, 4966.59009914],\n",
       "       [6311.55171945, 5238.02988664, 4827.68959976, ..., 4712.36958315,\n",
       "        6709.33652751, 5466.25141404],\n",
       "       ...,\n",
       "       [5170.08339662, 4276.66916473, 4712.36958315, ..., 3475.54341258,\n",
       "        5470.56697133, 4469.84941074],\n",
       "       [7519.22038154, 6153.95870759, 6709.33652751, ..., 5470.56697133,\n",
       "        6614.79569521, 6423.28161707],\n",
       "       [6039.28713657, 4966.59009914, 5466.25141404, ..., 4469.84941074,\n",
       "        6423.28161707, 4491.14331428]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joint_entropy_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "017c7f3e-53b7-49cb-ac3e-bb7a476cbba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_info_matrix(expr_mat, gridsize=(100,100), norm=True):\n",
    "\n",
    "    n = expr_mat.shape[-1]\n",
    "    j_entropies = pool_joint_entropy(expr_mat,step=5,epsilon=1e-100,gridsize=gridsize,t_sleep=1)\n",
    "    entropies = j_entropies.diagonal()\n",
    "    entropies_tile = np.tile(entropies, (n, 1))\n",
    "    sum_entropies = entropies_tile + entropies_tile.T\n",
    "    mi_matrix = sum_entropies - j_entropies\n",
    "    if norm:\n",
    "        mi_matrix = mi_matrix * 2 / sum_entropies\n",
    "        #mi_matrix = mi_matrix / np.sqrt(entropies_tile * entropies_tile.T)\n",
    "    return mi_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ba86b6d-a164-41bc-b2e9-019c1a86a7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM Usage: 75.6% | CPU Usage: 89.8%\n",
      "RAM Usage: 78.0% | CPU Usage: 89.2%\n",
      "RAM Usage: 78.0% | CPU Usage: 100.0%\n",
      "RAM Usage: 77.9% | CPU Usage: 100.0%\n",
      "RAM Usage: 77.9% | CPU Usage: 100.0%\n",
      "RAM Usage: 77.8% | CPU Usage: 100.0%\n",
      "RAM Usage: 77.9% | CPU Usage: 100.0%\n",
      "RAM Usage: 77.9% | CPU Usage: 100.0%\n",
      "RAM Usage: 77.9% | CPU Usage: 100.0%\n",
      "RAM Usage: 77.9% | CPU Usage: 100.0%\n"
     ]
    }
   ],
   "source": [
    "mi_matrix = mutual_info_matrix(expr_mat_wnt_trim, gridsize=(100,100), norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9efad156-d698-47e5-a49f-7300a5beba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_matrix_edge = np.where(mi_matrix>=0.9,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "478f3191-3c02-41cd-bb5c-521e0bb4e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fill_diagonal(mi_matrix_edge,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8b44be8-44bb-4afc-ad88-a4d72f1ee9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_matrix_edge[0:5,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6bb0b621-b30a-4568-97ab-257eae64f4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(mi_matrix_edge,index=list(set(genes_wnt_dge + genes_corr_mat)),columns=list(set(genes_wnt_dge + genes_corr_mat))).to_csv('/home/thomas/Documents/git/medulloblastoma_cavalli_kaggle/data/network/mi_matrix_edge.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
